# Load model directly
from transformers import AutoTokenizer, AutoModelForMaskedLM

tokenizer = AutoTokenizer.from_pretrained("huggingface/CodeBERTa-small-v1")
# model = AutoModelForMaskedLM.from_pretrained("huggingface/CodeBERTa-small-v1")

output = tokenizer.encode('\t\t\t @Parameters(commandDescription = "Frequency count a structured input instance file.")\n   \t ')
output = tokenizer.encode('\tè¿™æ˜¯ä¸€æ®µä¸´æ—¶æµ‹è¯•ï¼Œæµ‹è¯•æ˜¯å¦èƒ½å¤Ÿç¼–ç ã€‚ğŸ˜‚')
print(output)
print(tokenizer.decode(output))