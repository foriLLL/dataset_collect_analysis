# Load model directly
from transformers import AutoTokenizer, AutoModelForMaskedLM

tokenizer = AutoTokenizer.from_pretrained("huggingface/CodeBERTa-small-v1")

def encode(text: str):
    return tokenizer.encode(text)

def decode(token_ids: list[int]):
    return tokenizer.convert_ids_to_tokens(token_ids)

if __name__ == '__main__':
    output = encode('\t\t\t @Parameters(commandDescription = "Frequency count a structured input instance file.")\n   \t ')
    output = encode('\tè¿™æ˜¯ä¸€æ®µä¸´æ—¶æµ‹è¯•ï¼Œæµ‹è¯•æ˜¯å¦èƒ½å¤Ÿç¼–ç ã€‚ğŸ˜‚')
    output = encode('')
    print(output)
    print(tokenizer.convert_ids_to_tokens(output))